{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df[['label', 'hour']][train_df['label'] == 1].groupby(['hour']).count().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conversion rate vs advertiser_id\n",
    "conversion= train_df[['label', 'advertiser_id']][train_df['label'] == 1].groupby(['advertiser_id']).count()\n",
    "conversion['all'] = train_df[['label', 'advertiser_id']].groupby(['advertiser_id']).count()\n",
    "conversion['conversion_rate'] = conversion['label']*100/conversion['all']\n",
    "conversion['conversion_rate'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conversion rate vs ad_type\n",
    "conversion= train_df[['label', 'ad_type']][train_df['label'] == 1].groupby(['ad_type']).count()\n",
    "conversion['all'] = train_df[['label', 'ad_type']].groupby(['ad_type']).count()\n",
    "conversion['conversion_rate'] = conversion['label']*100/conversion['all']\n",
    "#conversion['conversion_rate'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conversion rate vs detect_type\n",
    "conversion= train_df[['label', 'detect_type']][train_df['label'] == 1].groupby(['detect_type']).count()\n",
    "conversion['all'] = train_df[['label', 'detect_type']].groupby(['detect_type']).count()\n",
    "conversion['conversion_rate'] = conversion['label']*100/conversion['all']\n",
    "#conversion['conversion_rate'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conversion rate vs direct\n",
    "conversion= train_df[['label', 'direct']][train_df['label'] == 1].groupby(['direct']).count()\n",
    "conversion['all'] = train_df[['label', 'direct']].groupby(['direct']).count()\n",
    "conversion['conversion_rate'] = conversion['label']*100/conversion['all']\n",
    "#conversion['conversion_rate'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conversion rate vs image_size\n",
    "conversion= train_df[['label', 'image_size']][train_df['label'] == 1].groupby(['image_size']).count()\n",
    "conversion['all'] = train_df[['label', 'image_size']].groupby(['image_size']).count()\n",
    "conversion['conversion_rate'] = conversion['label']*100/conversion['all']\n",
    "#conversion['conversion_rate'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conversion rate vs package_category\n",
    "conversion= train_df[['label', 'package_category']][train_df['label'] == 1].groupby(['package_category']).count()\n",
    "conversion['all'] = train_df[['label', 'package_category']].groupby(['package_category']).count()\n",
    "conversion['conversion_rate'] = conversion['label']*100/conversion['all']\n",
    "# conversion['conversion_rate'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conversion rate vs package_comment_count\n",
    "conversion= train_df[['label', 'package_comment_count']][train_df['label'] == 1].groupby(['package_comment_count']).count()\n",
    "conversion['all'] = train_df[['label', 'package_comment_count']].groupby(['package_comment_count']).count()\n",
    "conversion['conversion_rate'] = conversion['label']*100/conversion['all']\n",
    "# conversion['conversion_rate'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conversion rate vs package_install_num\n",
    "conversion_raw = train_df[['label', 'package_install_num']][train_df['package_install_num'] != 'none']\n",
    "conversion_raw['package_install_num'] = conversion_raw.package_install_num.astype(float)\n",
    "conversion = conversion_raw[conversion_raw['label'] == 1].groupby(['package_install_num']).count()\n",
    "conversion['all'] = conversion_raw.groupby(['package_install_num']).count()\n",
    "conversion['conversion_rate'] = conversion['label']*100/conversion['all']\n",
    "conversion.sort_index(inplace=True)\n",
    "# conversion['conversion_rate'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conversion rate vs package_rate\n",
    "conversion_raw = train_df[['label', 'package_rate']][train_df['package_rate'] != 'none']\n",
    "conversion_raw['package_rate'] = conversion_raw.package_rate.astype(float)\n",
    "conversion = conversion_raw[conversion_raw['label'] == 1].groupby(['package_rate']).count()\n",
    "conversion['all'] = conversion_raw.groupby(['package_rate']).count()\n",
    "conversion['conversion_rate'] = conversion['label']*100/conversion['all']\n",
    "conversion.sort_index(inplace=True)\n",
    "# conversion['conversion_rate'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conversion rate vs package_size\n",
    "conversion= train_df[['label', 'package_size']][train_df['label'] == 1].groupby(['package_size']).count()\n",
    "conversion['all'] = train_df[['label', 'package_size']].groupby(['package_size']).count()\n",
    "conversion['conversion_rate'] = conversion['label']*100/conversion['all']\n",
    "# conversion['conversion_rate'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conversion rate vs package_total_rating_num\n",
    "conversion_raw = train_df[['label', 'package_total_rating_num']][train_df['package_total_rating_num'] != 'none']\n",
    "conversion_raw['package_total_rating_num'] = conversion_raw.package_total_rating_num.astype(float)\n",
    "conversion = conversion_raw[conversion_raw['label'] == 1].groupby(['package_total_rating_num']).count()\n",
    "conversion['all'] = conversion_raw.groupby(['package_total_rating_num']).count()\n",
    "conversion['conversion_rate'] = conversion['label']*100/conversion['all']\n",
    "conversion.sort_index(inplace=True)\n",
    "# conversion['conversion_rate'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conversion rate vs jump_count\n",
    "conversion_raw = train_df[['label', 'jump_count']][train_df['jump_count'] != 'none']\n",
    "conversion_raw['jump_count'] = conversion_raw.jump_count.astype(float)\n",
    "conversion = conversion_raw[conversion_raw['label'] == 1].groupby(['jump_count']).count()\n",
    "conversion['all'] = conversion_raw.groupby(['jump_count']).count()\n",
    "conversion['conversion_rate'] = conversion['label']*100/conversion['all']\n",
    "conversion.sort_index(inplace=True)\n",
    "# conversion['conversion_rate'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conversion rate vs platform\n",
    "conversion= train_df[['label', 'platform']][train_df['label'] == 1].groupby(['platform']).count()\n",
    "conversion['all'] = train_df[['label', 'platform']].groupby(['platform']).count()\n",
    "conversion['conversion_rate'] = conversion['label']*100/conversion['all']\n",
    "# conversion['conversion_rate'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First order feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Select_auc = ''\n",
    "Select_log = ''\n",
    "AUC = 0\n",
    "log = 10\n",
    "for feature in ['ad_type', 'appid_category', 'country_code', \n",
    " 'device_brand', 'direct', 'dmp_tag', 'hour', 'jump_count', 'language', 'mcc_mnc',\n",
    " 'orientatioin', 'os_version', \n",
    " 'package_rate', 'package_subcategory', 'package_total_rating_num', 'device_brand_binned_cat']:\n",
    "    feature_cols = ['unit_id', 'campaign_id', 'device_model', 'advertiser_id', 'app_id', 'image_size', 'package_name', 'sdk_version', 'network_type', 'country_code', 'package_install_num', 'platform', 'detect_type', 'package_size', 'package_category'] + [feature]\n",
    "    cat_features = ['unit_id', 'campaign_id', 'device_model', 'advertiser_id', 'app_id', 'image_size', 'package_name', 'sdk_version', 'network_type', 'country_code', 'package_install_num', 'platform', 'detect_type', 'package_size', 'package_category'] + [feature]\n",
    "    cont_features = []\n",
    "    interac_features = []\n",
    "    \n",
    "    # print \"Preprocessing Data...\"\n",
    "    train_df = create_features(train)\n",
    "    train_df = train_df[feature_cols + ['label']].copy().reset_index(drop=True)\n",
    "    X_train, y_train = train_df, train_df.pop('label')\n",
    "    #print \"Hashing Features...\"\n",
    "    feature_creator = FeatureCreator()\n",
    "    design_matrix_transformer = FeatureHasher(22, cat_features, cont_features, interac_features, store_fmap=True)\n",
    "    X_train = feature_creator.transform(X_train, inplace=True)\n",
    "    X_train, f_map = design_matrix_transformer.fit_transform(X_train)\n",
    "    \n",
    "    #print \"Updating Model...\"\n",
    "    m.fit(X_train, y_train)\n",
    "\n",
    "    del train_df\n",
    "    m.n_iter_\n",
    "    \n",
    "    #print \"Preprocessing Data...\"\n",
    "    test_df = create_features(test)\n",
    "    test_df = test_df[feature_cols + ['label', 'Unnamed: 0']].copy().reset_index(drop=True)\n",
    "    X_test, y_test = test_df, test_df.pop('label')\n",
    "    #print \" \"\n",
    "    X_test = feature_creator.transform(X_test, inplace=True)\n",
    "    X_test, f_map = design_matrix_transformer.fit_transform(X_test)\n",
    "    y_pred_prob = m.predict_proba(X_test)[:, 1]\n",
    "    print '\\t %s AUC score: %2f' % (feature, roc_auc_score(y_test, y_pred_prob))\n",
    "    print '\\t %s log loss score: %2f'% (feature, log_loss(y_test, y_pred_prob))\n",
    "    if roc_auc_score(y_test, y_pred_prob) > AUC:\n",
    "        AUC = roc_auc_score(y_test, y_pred_prob)\n",
    "        Select_auc = feature\n",
    "    if log_loss(y_test, y_pred_prob) < log:\n",
    "        log = log_loss(y_test, y_pred_prob)\n",
    "        Select_log = feature        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = LogisticRegression(C=0.1)\n",
    "Select_auc = ''\n",
    "Select_log = ''\n",
    "AUC = 0\n",
    "log = 10\n",
    "\n",
    "Select_auc_cv = ''\n",
    "AUC_cv = 0\n",
    "\n",
    "for feature in ['device_brand', 'hour', 'language', 'mcc_mnc',\n",
    " 'orientatioin', 'os_version', \n",
    " 'package_rate', 'package_total_rating_num', 'device_brand_binned_cat',\n",
    " 'image_size', \n",
    " 'package_size', 'package_category']:\n",
    "    feature_cols = ['unit_id', 'campaign_id', 'advertiser_id', 'app_id', 'package_name', 'ad_type', 'sdk_version', 'country_code', 'platform', 'dmp_tag', 'device_model', 'network_type', 'package_install_num', 'appid_category', 'detect_type', 'jump_count', 'package_subcategory', 'direct'] + [feature]\n",
    "    cat_features = ['unit_id', 'campaign_id', 'advertiser_id', 'app_id', 'package_name', 'ad_type', 'sdk_version', 'country_code', 'platform', 'dmp_tag', 'device_model', 'network_type', 'package_install_num', 'appid_category', 'detect_type', 'jump_count', 'package_subcategory', 'direct'] + [feature]\n",
    "    cont_features = []\n",
    "    interac_features = []\n",
    "    \n",
    "    # print \"Preprocessing Data...\"\n",
    "    train_df = create_features(train)\n",
    "    train_df = train_df[feature_cols + ['label']].copy().reset_index(drop=True)\n",
    "    X_train, y_train = train_df, train_df.pop('label')\n",
    "    #print \"Hashing Features...\"\n",
    "    feature_creator = FeatureCreator()\n",
    "    design_matrix_transformer = FeatureHasher(19, cat_features, cont_features, interac_features, store_fmap=True)\n",
    "    X_train = feature_creator.transform(X_train, inplace=True)\n",
    "    X_train, f_map = design_matrix_transformer.fit_transform(X_train)\n",
    "    \n",
    "    results = model_selection.cross_val_score(m, X_train, y_train, cv=kfold, scoring='roc_auc')\n",
    "    print(\"%s CV Accuracy: %.3f (%.3f)\") % (feature, results.mean(), results.std())\n",
    "    if results.mean() > AUC_cv:\n",
    "        AUC_cv = results.mean()\n",
    "        Select_auc_cv = feature\n",
    "\n",
    "    #print \"Updating Model...\"\n",
    "    m.fit(X_train, y_train)\n",
    "\n",
    "    del train_df\n",
    "    m.n_iter_\n",
    "    \n",
    "    #print \"Preprocessing Data...\"\n",
    "    test_df = create_features(test)\n",
    "    test_df = test_df[feature_cols + ['label', 'Unnamed: 0']].copy().reset_index(drop=True)\n",
    "    X_test, y_test = test_df, test_df.pop('label')\n",
    "    #print \" \"\n",
    "    X_test = feature_creator.transform(X_test, inplace=True)\n",
    "    X_test, f_map = design_matrix_transformer.fit_transform(X_test)\n",
    "    y_pred_prob = m.predict_proba(X_test)[:, 1]\n",
    "    print '\\t %s AUC score: %2f' % (feature, roc_auc_score(y_test, y_pred_prob))\n",
    "    print '\\t %s log loss score: %2f'% (feature, log_loss(y_test, y_pred_prob))\n",
    "    if roc_auc_score(y_test, y_pred_prob) > AUC:\n",
    "        AUC = roc_auc_score(y_test, y_pred_prob)\n",
    "        Select_auc = feature\n",
    "    if log_loss(y_test, y_pred_prob) < log:\n",
    "        log = log_loss(y_test, y_pred_prob)\n",
    "        Select_log = feature   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second order Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Select_auc = ''\n",
    "Select_log = ''\n",
    "AUC = 0\n",
    "log = 10\n",
    "for feature in [('unit_id', 'campaign_id'),\n",
    " ('unit_id', 'device_model'),\n",
    " ('unit_id', 'advertiser_id'),\n",
    " ('unit_id', 'package_name'),\n",
    " ('campaign_id', 'device_model'),\n",
    " ('campaign_id', 'image_size'),\n",
    " ('device_model', 'advertiser_id'),\n",
    " ('device_model', 'app_id'),\n",
    " ('device_model', 'image_size'),\n",
    " ('device_model', 'package_name'),\n",
    " ('app_id', 'package_name')]:\n",
    "    feature_cols = ['unit_id', 'campaign_id', 'device_model', 'advertiser_id', 'app_id', 'image_size', 'package_name', 'sdk_version', 'network_type', 'country_code', 'package_install_num', 'platform', 'detect_type', 'package_size', 'package_category']\n",
    "    cat_features = ['unit_id', 'campaign_id', 'device_model', 'advertiser_id', 'app_id', 'image_size', 'package_name', 'sdk_version', 'network_type', 'country_code', 'package_install_num', 'platform', 'detect_type', 'package_size', 'package_category']\n",
    "    cont_features = []\n",
    "    interac_features = [('advertiser_id', 'package_name'), ('app_id', 'image_size'), ('advertiser_id', 'app_id'), ('unit_id', 'app_id'), ('campaign_id', 'package_name'), ('image_size', 'package_name'), ('unit_id', 'image_size'), ('campaign_id', 'advertiser_id'),  ('advertiser_id', 'image_size'),('campaign_id', 'app_id')] + [feature]\n",
    "    \n",
    "    # print \"Preprocessing Data...\"\n",
    "    train_df = create_features(train)\n",
    "    train_df = train_df[feature_cols + ['label']].copy().reset_index(drop=True)\n",
    "    X_train, y_train = train_df, train_df.pop('label')\n",
    "    #print \"Hashing Features...\"\n",
    "    feature_creator = FeatureCreator()\n",
    "    design_matrix_transformer = FeatureHasher(22, cat_features, cont_features, interac_features, store_fmap=True)\n",
    "    X_train = feature_creator.transform(X_train, inplace=True)\n",
    "    X_train, f_map = design_matrix_transformer.fit_transform(X_train)\n",
    "    \n",
    "    #print \"Updating Model...\"\n",
    "    m.fit(X_train, y_train)\n",
    "\n",
    "    del train_df\n",
    "    m.n_iter_\n",
    "    \n",
    "    #print \"Preprocessing Data...\"\n",
    "    test_df = create_features(test)\n",
    "    test_df = test_df[feature_cols + ['label', 'Unnamed: 0']].copy().reset_index(drop=True)\n",
    "    X_test, y_test = test_df, test_df.pop('label')\n",
    "    #print \" \"\n",
    "    X_test = feature_creator.transform(X_test, inplace=True)\n",
    "    X_test, f_map = design_matrix_transformer.fit_transform(X_test)\n",
    "    y_pred_prob = m.predict_proba(X_test)[:, 1]\n",
    "    print '\\t %s AUC score: %2f' % (feature, roc_auc_score(y_test, y_pred_prob))\n",
    "    print '\\t %s log loss score: %2f'% (feature, log_loss(y_test, y_pred_prob))\n",
    "    if roc_auc_score(y_test, y_pred_prob) > AUC:\n",
    "        AUC = roc_auc_score(y_test, y_pred_prob)\n",
    "        Select_auc = feature\n",
    "    if log_loss(y_test, y_pred_prob) < log:\n",
    "        log = log_loss(y_test, y_pred_prob)\n",
    "        Select_log = feature        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "print '---------------------------------------'\n",
    "print 'Start Decision Tree...'\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "model = ExtraTreesClassifier(n_estimators=250, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_prob = model.predict(X_test)\n",
    "print 'AUC score: %2f' % roc_auc_score(y_test, y_pred_prob)\n",
    "print 'log loss score: %2f'% log_loss(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LDA\n",
    "print '---------------------------------------'\n",
    "print 'Start LDA...'\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "model = LinearDiscriminantAnalysis()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_prob = model.predict_proba(X_test)\n",
    "print 'AUC score: %2f' % roc_auc_score(y_test, y_pred_prob)\n",
    "print 'log loss score: %2f'% log_loss(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "print '---------------------------------------'\n",
    "print 'Start Random forest...'\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "print 'AUC score: %2f' % roc_auc_score(y_test, y_pred_prob)\n",
    "print 'log loss score: %2f'% log_loss(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "print '---------------------------------------'\n",
    "print 'Start XGBoost...'\n",
    "import xgboost\n",
    "\n",
    "model = xgboost.XGBClassifier(max_depth = 2, silent  = 1, objective = 'binary:logistic')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "print 'AUC score: %2f' % roc_auc_score(y_test, y_pred_prob)\n",
    "print 'log loss score: %2f'% log_loss(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nerual Network\n",
    "print '---------------------------------------'\n",
    "print 'Start Neral Network...'\n",
    "\n",
    "\n",
    "model = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring='roc_auc')\n",
    "print(\"CV AUC score: %.3f (%.3f)\") % (results.mean(), results.std())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "print 'AUC score: %2f' % roc_auc_score(y_test, y_pred_prob)\n",
    "print 'log loss score: %2f'% log_loss(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "CV_rfc = GridSearchCV(estimator=model, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(X_train, y_train)\n",
    "print CV_rfc.best_params_\n",
    "# {'C': 0.1}\n",
    "print CV_rfc.best_score_\n",
    "# 0.996915555556"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-156908512"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmh3.hash('foo', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mmh3\n",
    "\n",
    "def _murmur_32s(key, seed):\n",
    "    if isinstance(key, unicode):\n",
    "        bkey = key.encode('utf-8')\n",
    "    elif isinstance(key, bytes):\n",
    "        bkey = key\n",
    "    else:\n",
    "        print key\n",
    "        raise ValueError(\"the key %s must be either unicode or str\"% key)\n",
    "    return mmh3.hash(bkey, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1094219900"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmh3.hash('490', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "524287"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 ** 19 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-0124313 >= 0) * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
